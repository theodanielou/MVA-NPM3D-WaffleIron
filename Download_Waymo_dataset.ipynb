{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "! gcloud auth login"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "324giI8Yflp0",
        "outputId": "63b1f538-025e-4950-88eb-2be73b18c886"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Go to the following link in your browser:\n",
            "\n",
            "    https://accounts.google.com/o/oauth2/auth?response_type=code&client_id=32555940559.apps.googleusercontent.com&redirect_uri=https%3A%2F%2Fsdk.cloud.google.com%2Fauthcode.html&scope=openid+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fuserinfo.email+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fcloud-platform+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fappengine.admin+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fsqlservice.login+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fcompute+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Faccounts.reauth&state=xZmbOScH5EasUflhGN2FL4aEtBP9W9&prompt=consent&token_usage=remote&access_type=offline&code_challenge=us9Ye1gU1Zig2UQZ0LOZxSWjof_5rUWcUHauOp8zKT0&code_challenge_method=S256\n",
            "\n",
            "Enter authorization code: 4/0AeaYSHBpgfd_jP-vaVNX-S2PZKRDJcczINYWjpeE-CW0b7I-BhfAtjuUVqgWIY9StwnArQ\n",
            "\n",
            "You are now logged in as [theo.danielou33@gmail.com].\n",
            "Your current project is [None].  You can change this setting by running:\n",
            "  $ gcloud config set project PROJECT_ID\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! mkdir lidar\n",
        "! mkdir lidar_segmentation\n",
        "! mkdir lidar_camera_projection\n",
        "! mkdir lidar_calibration\n",
        "! mkdir stats\n",
        "! mkdir vehicle_pose\n",
        "! mkdir lidar_pose\n",
        "\n",
        "# essaie lui 10096619443888687526_2820_000_2840_000 (plus lourd )\n",
        "\n",
        "# ce que je testais 15832924468527961_1564_160_1584_160"
      ],
      "metadata": {
        "id": "qDov3H9QjmdJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "685ff62e-f0c5-4075-89be-e660a5c9e08c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘lidar’: File exists\n",
            "mkdir: cannot create directory ‘lidar_segmentation’: File exists\n",
            "mkdir: cannot create directory ‘lidar_camera_projection’: File exists\n",
            "mkdir: cannot create directory ‘lidar_calibration’: File exists\n",
            "mkdir: cannot create directory ‘stats’: File exists\n",
            "mkdir: cannot create directory ‘vehicle_pose’: File exists\n",
            "mkdir: cannot create directory ‘lidar_pose’: File exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! gsutil cp gs://waymo_open_dataset_v_2_0_0/training/lidar/10096619443888687526_2820_000_2840_000.parquet ./lidar"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HNfD5qEIqawe",
        "outputId": "342c8083-5c77-4754-faa1-616cdb4e9801"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Copying gs://waymo_open_dataset_v_2_0_0/training/lidar/10096619443888687526_2820_000_2840_000.parquet...\n",
            "/ [0 files][    0.0 B/194.1 MiB]                                                \r==> NOTE: You are downloading one or more large file(s), which would\n",
            "run significantly faster if you enabled sliced object downloads. This\n",
            "feature is enabled by default but requires that compiled crcmod be\n",
            "installed (see \"gsutil help crcmod\").\n",
            "\n",
            "/ [1 files][194.1 MiB/194.1 MiB]                                                \n",
            "Operation completed over 1 objects/194.1 MiB.                                    \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! gsutil cp gs://waymo_open_dataset_v_2_0_0/training/lidar_pose/10096619443888687526_2820_000_2840_000.parquet ./lidar_pose"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EbIlnyGlpyEp",
        "outputId": "7f8bf5d6-d516-4221-940b-cc2a7dd219b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Copying gs://waymo_open_dataset_v_2_0_0/training/lidar_pose/10096619443888687526_2820_000_2840_000.parquet...\n",
            "/ [1 files][ 24.1 MiB/ 24.1 MiB]                                                \n",
            "Operation completed over 1 objects/24.1 MiB.                                     \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! gsutil cp gs://waymo_open_dataset_v_2_0_0/training/lidar_segmentation/10096619443888687526_2820_000_2840_000.parquet ./lidar_segmentation"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tdQ9_5QSqoNM",
        "outputId": "003414ff-f884-4201-a8d4-a6156e557b97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Copying gs://waymo_open_dataset_v_2_0_0/training/lidar_segmentation/10096619443888687526_2820_000_2840_000.parquet...\n",
            "/ [1 files][991.6 KiB/991.6 KiB]                                                \n",
            "Operation completed over 1 objects/991.6 KiB.                                    \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! gsutil cp gs://waymo_open_dataset_v_2_0_0/training/lidar_camera_projection/10096619443888687526_2820_000_2840_000.parquet ./lidar_camera_projection"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2t7tXjXmqtga",
        "outputId": "52d66154-8b04-4f7a-b789-f1b7d9422eb5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Copying gs://waymo_open_dataset_v_2_0_0/training/lidar_camera_projection/10096619443888687526_2820_000_2840_000.parquet...\n",
            "- [1 files][ 85.0 MiB/ 85.0 MiB]                                                \n",
            "Operation completed over 1 objects/85.0 MiB.                                     \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! gsutil cp gs://waymo_open_dataset_v_2_0_0/training/lidar_calibration/10096619443888687526_2820_000_2840_000.parquet ./lidar_calibration"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DIVAvIYlqxyg",
        "outputId": "2114221a-b4c4-4614-e264-481ce943ff1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Copying gs://waymo_open_dataset_v_2_0_0/training/lidar_calibration/10096619443888687526_2820_000_2840_000.parquet...\n",
            "/ [0 files][    0.0 B/  4.7 KiB]                                                \r/ [1 files][  4.7 KiB/  4.7 KiB]                                                \r\n",
            "Operation completed over 1 objects/4.7 KiB.                                      \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! gsutil cp gs://waymo_open_dataset_v_2_0_0/training/stats/10096619443888687526_2820_000_2840_000.parquet ./stats"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "945PIJ2CpNwD",
        "outputId": "6265c52c-1d98-4149-8c2a-7ac62fbde0d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Copying gs://waymo_open_dataset_v_2_0_0/training/stats/10096619443888687526_2820_000_2840_000.parquet...\n",
            "/ [1 files][ 22.6 KiB/ 22.6 KiB]                                                \n",
            "Operation completed over 1 objects/22.6 KiB.                                     \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! gsutil cp gs://waymo_open_dataset_v_2_0_0/training/vehicle_pose/10096619443888687526_2820_000_2840_000.parquet ./vehicle_pose"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w33tECa7pBZc",
        "outputId": "51b3cd91-ae3e-412b-e60a-e98130679cb0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Copying gs://waymo_open_dataset_v_2_0_0/training/vehicle_pose/10096619443888687526_2820_000_2840_000.parquet...\n",
            "/ [0 files][    0.0 B/ 37.6 KiB]                                                \r/ [1 files][ 37.6 KiB/ 37.6 KiB]                                                \r\n",
            "Operation completed over 1 objects/37.6 KiB.                                     \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! python3 -m pip install gcsfs waymo-open-dataset-tf-2-11-0==1.6.1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DxjQFLYwq13i",
        "outputId": "7351089c-df7d-4ca4-ab6f-91843f3104b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gcsfs in /usr/local/lib/python3.10/dist-packages (2023.6.0)\n",
            "Collecting waymo-open-dataset-tf-2-11-0==1.6.1\n",
            "  Downloading waymo_open_dataset_tf_2_11_0-1.6.1-py3-none-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (4.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: absl-py==1.4.0 in /usr/local/lib/python3.10/dist-packages (from waymo-open-dataset-tf-2-11-0==1.6.1) (1.4.0)\n",
            "Collecting dask[dataframe]==2023.3.1 (from waymo-open-dataset-tf-2-11-0==1.6.1)\n",
            "  Downloading dask-2023.3.1-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m63.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting einsum==0.3.0 (from waymo-open-dataset-tf-2-11-0==1.6.1)\n",
            "  Downloading einsum-0.3.0-py3-none-any.whl (5.1 kB)\n",
            "Collecting google-auth==2.16.2 (from waymo-open-dataset-tf-2-11-0==1.6.1)\n",
            "  Downloading google_auth-2.16.2-py2.py3-none-any.whl (177 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.2/177.2 kB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting immutabledict==2.2.0 (from waymo-open-dataset-tf-2-11-0==1.6.1)\n",
            "  Downloading immutabledict-2.2.0-py3-none-any.whl (4.0 kB)\n",
            "Collecting matplotlib==3.6.1 (from waymo-open-dataset-tf-2-11-0==1.6.1)\n",
            "  Downloading matplotlib-3.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m67.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting numpy==1.21.5 (from waymo-open-dataset-tf-2-11-0==1.6.1)\n",
            "  Downloading numpy-1.21.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.9/15.9 MB\u001b[0m \u001b[31m60.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting openexr==1.3.9 (from waymo-open-dataset-tf-2-11-0==1.6.1)\n",
            "  Downloading OpenEXR-1.3.9-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m63.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas==1.5.3 in /usr/local/lib/python3.10/dist-packages (from waymo-open-dataset-tf-2-11-0==1.6.1) (1.5.3)\n",
            "Collecting pillow==9.2.0 (from waymo-open-dataset-tf-2-11-0==1.6.1)\n",
            "  Downloading Pillow-9.2.0-cp310-cp310-manylinux_2_28_x86_64.whl (3.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m68.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting plotly==5.13.1 (from waymo-open-dataset-tf-2-11-0==1.6.1)\n",
            "  Downloading plotly-5.13.1-py2.py3-none-any.whl (15.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.2/15.2 MB\u001b[0m \u001b[31m66.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyarrow==10.0.0 (from waymo-open-dataset-tf-2-11-0==1.6.1)\n",
            "  Downloading pyarrow-10.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (35.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.2/35.2 MB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scikit-image==0.20.0 (from waymo-open-dataset-tf-2-11-0==1.6.1)\n",
            "  Downloading scikit_image-0.20.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.2/13.2 MB\u001b[0m \u001b[31m52.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scikit-learn==1.2.2 in /usr/local/lib/python3.10/dist-packages (from waymo-open-dataset-tf-2-11-0==1.6.1) (1.2.2)\n",
            "Collecting setuptools==67.6.0 (from waymo-open-dataset-tf-2-11-0==1.6.1)\n",
            "  Downloading setuptools-67.6.0-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m64.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow==2.11 (from waymo-open-dataset-tf-2-11-0==1.6.1)\n",
            "  Downloading tensorflow-2.11.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (588.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m588.3/588.3 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow_graphics==2021.12.3 (from waymo-open-dataset-tf-2-11-0==1.6.1)\n",
            "  Downloading tensorflow_graphics-2021.12.3-py3-none-any.whl (4.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.3/4.3 MB\u001b[0m \u001b[31m78.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow_probability==0.19.0 (from waymo-open-dataset-tf-2-11-0==1.6.1)\n",
            "  Downloading tensorflow_probability-0.19.0-py2.py3-none-any.whl (6.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.7/6.7 MB\u001b[0m \u001b[31m94.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting visu3d==1.5.1 (from waymo-open-dataset-tf-2-11-0==1.6.1)\n",
            "  Downloading visu3d-1.5.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dacite==1.8.1 (from waymo-open-dataset-tf-2-11-0==1.6.1)\n",
            "  Downloading dacite-1.8.1-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from dask[dataframe]==2023.3.1->waymo-open-dataset-tf-2-11-0==1.6.1) (8.1.7)\n",
            "Requirement already satisfied: cloudpickle>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from dask[dataframe]==2023.3.1->waymo-open-dataset-tf-2-11-0==1.6.1) (2.2.1)\n",
            "Requirement already satisfied: fsspec>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from dask[dataframe]==2023.3.1->waymo-open-dataset-tf-2-11-0==1.6.1) (2023.6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from dask[dataframe]==2023.3.1->waymo-open-dataset-tf-2-11-0==1.6.1) (23.2)\n",
            "Requirement already satisfied: partd>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from dask[dataframe]==2023.3.1->waymo-open-dataset-tf-2-11-0==1.6.1) (1.4.1)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from dask[dataframe]==2023.3.1->waymo-open-dataset-tf-2-11-0==1.6.1) (6.0.1)\n",
            "Requirement already satisfied: toolz>=0.8.2 in /usr/local/lib/python3.10/dist-packages (from dask[dataframe]==2023.3.1->waymo-open-dataset-tf-2-11-0==1.6.1) (0.12.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth==2.16.2->waymo-open-dataset-tf-2-11-0==1.6.1) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth==2.16.2->waymo-open-dataset-tf-2-11-0==1.6.1) (0.3.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from google-auth==2.16.2->waymo-open-dataset-tf-2-11-0==1.6.1) (1.16.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth==2.16.2->waymo-open-dataset-tf-2-11-0==1.6.1) (4.9)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.6.1->waymo-open-dataset-tf-2-11-0==1.6.1) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.6.1->waymo-open-dataset-tf-2-11-0==1.6.1) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.6.1->waymo-open-dataset-tf-2-11-0==1.6.1) (4.49.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.6.1->waymo-open-dataset-tf-2-11-0==1.6.1) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.6.1->waymo-open-dataset-tf-2-11-0==1.6.1) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.6.1->waymo-open-dataset-tf-2-11-0==1.6.1) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas==1.5.3->waymo-open-dataset-tf-2-11-0==1.6.1) (2023.4)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly==5.13.1->waymo-open-dataset-tf-2-11-0==1.6.1) (8.2.3)\n",
            "Requirement already satisfied: scipy>=1.8 in /usr/local/lib/python3.10/dist-packages (from scikit-image==0.20.0->waymo-open-dataset-tf-2-11-0==1.6.1) (1.11.4)\n",
            "Requirement already satisfied: networkx>=2.8 in /usr/local/lib/python3.10/dist-packages (from scikit-image==0.20.0->waymo-open-dataset-tf-2-11-0==1.6.1) (3.2.1)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image==0.20.0->waymo-open-dataset-tf-2-11-0==1.6.1) (2.31.6)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image==0.20.0->waymo-open-dataset-tf-2-11-0==1.6.1) (2024.2.12)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image==0.20.0->waymo-open-dataset-tf-2-11-0==1.6.1) (1.5.0)\n",
            "Requirement already satisfied: lazy_loader>=0.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image==0.20.0->waymo-open-dataset-tf-2-11-0==1.6.1) (0.3)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.2.2->waymo-open-dataset-tf-2-11-0==1.6.1) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.2.2->waymo-open-dataset-tf-2-11-0==1.6.1) (3.3.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11->waymo-open-dataset-tf-2-11-0==1.6.1) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11->waymo-open-dataset-tf-2-11-0==1.6.1) (23.5.26)\n",
            "Collecting gast<=0.4.0,>=0.2.1 (from tensorflow==2.11->waymo-open-dataset-tf-2-11-0==1.6.1)\n",
            "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11->waymo-open-dataset-tf-2-11-0==1.6.1) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11->waymo-open-dataset-tf-2-11-0==1.6.1) (1.62.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11->waymo-open-dataset-tf-2-11-0==1.6.1) (3.9.0)\n",
            "Collecting keras<2.12,>=2.11.0 (from tensorflow==2.11->waymo-open-dataset-tf-2-11-0==1.6.1)\n",
            "  Downloading keras-2.11.0-py2.py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m71.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11->waymo-open-dataset-tf-2-11-0==1.6.1) (16.0.6)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11->waymo-open-dataset-tf-2-11-0==1.6.1) (3.3.0)\n",
            "Collecting protobuf<3.20,>=3.9.2 (from tensorflow==2.11->waymo-open-dataset-tf-2-11-0==1.6.1)\n",
            "  Downloading protobuf-3.19.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m67.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorboard<2.12,>=2.11 (from tensorflow==2.11->waymo-open-dataset-tf-2-11-0==1.6.1)\n",
            "  Downloading tensorboard-2.11.2-py3-none-any.whl (6.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m79.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow-estimator<2.12,>=2.11.0 (from tensorflow==2.11->waymo-open-dataset-tf-2-11-0==1.6.1)\n",
            "  Downloading tensorflow_estimator-2.11.0-py2.py3-none-any.whl (439 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m439.2/439.2 kB\u001b[0m \u001b[31m36.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11->waymo-open-dataset-tf-2-11-0==1.6.1) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11->waymo-open-dataset-tf-2-11-0==1.6.1) (4.10.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11->waymo-open-dataset-tf-2-11-0==1.6.1) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11->waymo-open-dataset-tf-2-11-0==1.6.1) (0.36.0)\n",
            "Collecting tensorflow-addons>=0.10.0 (from tensorflow_graphics==2021.12.3->waymo-open-dataset-tf-2-11-0==1.6.1)\n",
            "  Downloading tensorflow_addons-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (611 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m611.8/611.8 kB\u001b[0m \u001b[31m50.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorflow-datasets>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow_graphics==2021.12.3->waymo-open-dataset-tf-2-11-0==1.6.1) (4.9.4)\n",
            "Requirement already satisfied: psutil>=5.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow_graphics==2021.12.3->waymo-open-dataset-tf-2-11-0==1.6.1) (5.9.5)\n",
            "Requirement already satisfied: tqdm>=4.45.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow_graphics==2021.12.3->waymo-open-dataset-tf-2-11-0==1.6.1) (4.66.2)\n",
            "Collecting trimesh>=2.37.22 (from tensorflow_graphics==2021.12.3->waymo-open-dataset-tf-2-11-0==1.6.1)\n",
            "  Downloading trimesh-4.1.7-py3-none-any.whl (690 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m690.4/690.4 kB\u001b[0m \u001b[31m50.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from tensorflow_probability==0.19.0->waymo-open-dataset-tf-2-11-0==1.6.1) (4.4.2)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.10/dist-packages (from tensorflow_probability==0.19.0->waymo-open-dataset-tf-2-11-0==1.6.1) (0.1.8)\n",
            "Collecting dataclass_array (from visu3d==1.5.1->waymo-open-dataset-tf-2-11-0==1.6.1)\n",
            "  Downloading dataclass_array-1.5.1-py3-none-any.whl (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.5/43.5 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting einops (from visu3d==1.5.1->waymo-open-dataset-tf-2-11-0==1.6.1)\n",
            "  Downloading einops-0.7.0-py3-none-any.whl (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: etils[edc,enp,epath,epy,etree] in /usr/local/lib/python3.10/dist-packages (from visu3d==1.5.1->waymo-open-dataset-tf-2-11-0==1.6.1) (1.7.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from gcsfs) (3.9.3)\n",
            "Requirement already satisfied: google-auth-oauthlib in /usr/local/lib/python3.10/dist-packages (from gcsfs) (1.2.0)\n",
            "Requirement already satisfied: google-cloud-storage in /usr/local/lib/python3.10/dist-packages (from gcsfs) (2.8.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from gcsfs) (2.31.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs) (4.0.3)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib->gcsfs) (1.3.1)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage->gcsfs) (2.11.1)\n",
            "Requirement already satisfied: google-cloud-core<3.0dev,>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage->gcsfs) (2.3.3)\n",
            "Requirement already satisfied: google-resumable-media>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage->gcsfs) (2.7.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->gcsfs) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->gcsfs) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->gcsfs) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->gcsfs) (2024.2.2)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow==2.11->waymo-open-dataset-tf-2-11-0==1.6.1) (0.42.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-storage->gcsfs) (1.62.0)\n",
            "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.10/dist-packages (from google-resumable-media>=2.3.2->google-cloud-storage->gcsfs) (1.5.0)\n",
            "Requirement already satisfied: locket in /usr/local/lib/python3.10/dist-packages (from partd>=1.2.0->dask[dataframe]==2023.3.1->waymo-open-dataset-tf-2-11-0==1.6.1) (1.0.0)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth==2.16.2->waymo-open-dataset-tf-2-11-0==1.6.1) (0.5.1)\n",
            "INFO: pip is looking at multiple versions of pywavelets to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting PyWavelets>=1.1.1 (from scikit-image==0.20.0->waymo-open-dataset-tf-2-11-0==1.6.1)\n",
            "  Downloading PyWavelets-1.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m95.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib->gcsfs) (3.2.2)\n",
            "INFO: pip is looking at multiple versions of scipy to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting scipy>=1.8 (from scikit-image==0.20.0->waymo-open-dataset-tf-2-11-0==1.6.1)\n",
            "  Downloading scipy-1.12.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.4/38.4 MB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading scipy-1.11.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (36.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m36.4/36.4 MB\u001b[0m \u001b[31m34.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading scipy-1.11.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (36.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m36.3/36.3 MB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading scipy-1.11.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (36.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m36.3/36.3 MB\u001b[0m \u001b[31m34.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading scipy-1.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.4/34.4 MB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting google-auth-oauthlib (from gcsfs)\n",
            "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.12,>=2.11->tensorflow==2.11->waymo-open-dataset-tf-2-11-0==1.6.1) (3.5.2)\n",
            "Collecting tensorboard-data-server<0.7.0,>=0.6.0 (from tensorboard<2.12,>=2.11->tensorflow==2.11->waymo-open-dataset-tf-2-11-0==1.6.1)\n",
            "  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m93.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorboard-plugin-wit>=1.6.0 (from tensorboard<2.12,>=2.11->tensorflow==2.11->waymo-open-dataset-tf-2-11-0==1.6.1)\n",
            "  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m781.3/781.3 kB\u001b[0m \u001b[31m63.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.12,>=2.11->tensorflow==2.11->waymo-open-dataset-tf-2-11-0==1.6.1) (3.0.1)\n",
            "Collecting typeguard<3.0.0,>=2.7 (from tensorflow-addons>=0.10.0->tensorflow_graphics==2021.12.3->waymo-open-dataset-tf-2-11-0==1.6.1)\n",
            "  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets>=2.0.0->tensorflow_graphics==2021.12.3->waymo-open-dataset-tf-2-11-0==1.6.1) (2.3)\n",
            "INFO: pip is looking at multiple versions of tensorflow-datasets to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting tensorflow-datasets>=2.0.0 (from tensorflow_graphics==2021.12.3->waymo-open-dataset-tf-2-11-0==1.6.1)\n",
            "  Downloading tensorflow_datasets-4.9.3-py3-none-any.whl (5.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m86.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: array-record in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets>=2.0.0->tensorflow_graphics==2021.12.3->waymo-open-dataset-tf-2-11-0==1.6.1) (0.5.0)\n",
            "  Downloading tensorflow_datasets-4.9.2-py3-none-any.whl (5.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m88.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading tensorflow_datasets-4.9.1-py3-none-any.whl (5.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m74.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading tensorflow_datasets-4.9.0-py3-none-any.whl (5.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m92.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets>=2.0.0->tensorflow_graphics==2021.12.3->waymo-open-dataset-tf-2-11-0==1.6.1) (1.14.0)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets>=2.0.0->tensorflow_graphics==2021.12.3->waymo-open-dataset-tf-2-11-0==1.6.1) (0.10.2)\n",
            "Collecting lark (from dataclass_array->visu3d==1.5.1->waymo-open-dataset-tf-2-11-0==1.6.1)\n",
            "  Downloading lark-1.1.9-py3-none-any.whl (111 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.7/111.7 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: importlib_resources in /usr/local/lib/python3.10/dist-packages (from etils[edc,enp,epath,epy,etree]->visu3d==1.5.1->waymo-open-dataset-tf-2-11-0==1.6.1) (6.1.2)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.10/dist-packages (from etils[edc,enp,epath,epy,etree]->visu3d==1.5.1->waymo-open-dataset-tf-2-11-0==1.6.1) (3.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.12,>=2.11->tensorflow==2.11->waymo-open-dataset-tf-2-11-0==1.6.1) (2.1.5)\n",
            "INFO: pip is looking at multiple versions of tensorflow-metadata to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting tensorflow-metadata (from tensorflow-datasets>=2.0.0->tensorflow_graphics==2021.12.3->waymo-open-dataset-tf-2-11-0==1.6.1)\n",
            "  Downloading tensorflow_metadata-1.13.1-py3-none-any.whl (28 kB)\n",
            "  Downloading tensorflow_metadata-1.13.0-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.3/53.3 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tensorboard-plugin-wit, openexr, typeguard, tensorflow-estimator, tensorboard-data-server, setuptools, protobuf, plotly, pillow, numpy, lark, keras, immutabledict, gast, einsum, einops, dacite, trimesh, tensorflow_probability, tensorflow-addons, scipy, PyWavelets, pyarrow, google-auth, dask, tensorflow-metadata, scikit-image, matplotlib, google-auth-oauthlib, tensorflow-datasets, tensorboard, tensorflow, dataclass_array, visu3d, tensorflow_graphics, waymo-open-dataset-tf-2-11-0\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.15.0\n",
            "    Uninstalling tensorflow-estimator-2.15.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.15.0\n",
            "  Attempting uninstall: tensorboard-data-server\n",
            "    Found existing installation: tensorboard-data-server 0.7.2\n",
            "    Uninstalling tensorboard-data-server-0.7.2:\n",
            "      Successfully uninstalled tensorboard-data-server-0.7.2\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 67.7.2\n",
            "    Uninstalling setuptools-67.7.2:\n",
            "      Successfully uninstalled setuptools-67.7.2\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.20.3\n",
            "    Uninstalling protobuf-3.20.3:\n",
            "      Successfully uninstalled protobuf-3.20.3\n",
            "  Attempting uninstall: plotly\n",
            "    Found existing installation: plotly 5.15.0\n",
            "    Uninstalling plotly-5.15.0:\n",
            "      Successfully uninstalled plotly-5.15.0\n",
            "  Attempting uninstall: pillow\n",
            "    Found existing installation: Pillow 9.4.0\n",
            "    Uninstalling Pillow-9.4.0:\n",
            "      Successfully uninstalled Pillow-9.4.0\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.25.2\n",
            "    Uninstalling numpy-1.25.2:\n",
            "      Successfully uninstalled numpy-1.25.2\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.15.0\n",
            "    Uninstalling keras-2.15.0:\n",
            "      Successfully uninstalled keras-2.15.0\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.5.4\n",
            "    Uninstalling gast-0.5.4:\n",
            "      Successfully uninstalled gast-0.5.4\n",
            "  Attempting uninstall: tensorflow_probability\n",
            "    Found existing installation: tensorflow-probability 0.23.0\n",
            "    Uninstalling tensorflow-probability-0.23.0:\n",
            "      Successfully uninstalled tensorflow-probability-0.23.0\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.11.4\n",
            "    Uninstalling scipy-1.11.4:\n",
            "      Successfully uninstalled scipy-1.11.4\n",
            "  Attempting uninstall: PyWavelets\n",
            "    Found existing installation: PyWavelets 1.5.0\n",
            "    Uninstalling PyWavelets-1.5.0:\n",
            "      Successfully uninstalled PyWavelets-1.5.0\n",
            "  Attempting uninstall: pyarrow\n",
            "    Found existing installation: pyarrow 14.0.2\n",
            "    Uninstalling pyarrow-14.0.2:\n",
            "      Successfully uninstalled pyarrow-14.0.2\n",
            "  Attempting uninstall: google-auth\n",
            "    Found existing installation: google-auth 2.27.0\n",
            "    Uninstalling google-auth-2.27.0:\n",
            "      Successfully uninstalled google-auth-2.27.0\n",
            "  Attempting uninstall: dask\n",
            "    Found existing installation: dask 2023.8.1\n",
            "    Uninstalling dask-2023.8.1:\n",
            "      Successfully uninstalled dask-2023.8.1\n",
            "  Attempting uninstall: tensorflow-metadata\n",
            "    Found existing installation: tensorflow-metadata 1.14.0\n",
            "    Uninstalling tensorflow-metadata-1.14.0:\n",
            "      Successfully uninstalled tensorflow-metadata-1.14.0\n",
            "  Attempting uninstall: scikit-image\n",
            "    Found existing installation: scikit-image 0.19.3\n",
            "    Uninstalling scikit-image-0.19.3:\n",
            "      Successfully uninstalled scikit-image-0.19.3\n",
            "  Attempting uninstall: matplotlib\n",
            "    Found existing installation: matplotlib 3.7.1\n",
            "    Uninstalling matplotlib-3.7.1:\n",
            "      Successfully uninstalled matplotlib-3.7.1\n",
            "  Attempting uninstall: google-auth-oauthlib\n",
            "    Found existing installation: google-auth-oauthlib 1.2.0\n",
            "    Uninstalling google-auth-oauthlib-1.2.0:\n",
            "      Successfully uninstalled google-auth-oauthlib-1.2.0\n",
            "  Attempting uninstall: tensorflow-datasets\n",
            "    Found existing installation: tensorflow-datasets 4.9.4\n",
            "    Uninstalling tensorflow-datasets-4.9.4:\n",
            "      Successfully uninstalled tensorflow-datasets-4.9.4\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.15.2\n",
            "    Uninstalling tensorboard-2.15.2:\n",
            "      Successfully uninstalled tensorboard-2.15.2\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.15.0\n",
            "    Uninstalling tensorflow-2.15.0:\n",
            "      Successfully uninstalled tensorflow-2.15.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.34.0 requires jedi>=0.16, which is not installed.\n",
            "chex 0.1.85 requires numpy>=1.24.1, but you have numpy 1.21.5 which is incompatible.\n",
            "distributed 2023.8.1 requires dask==2023.8.1, but you have dask 2023.3.1 which is incompatible.\n",
            "flax 0.8.1 requires numpy>=1.22, but you have numpy 1.21.5 which is incompatible.\n",
            "google-colab 1.0.0 requires google-auth==2.27.0, but you have google-auth 2.16.2 which is incompatible.\n",
            "jax 0.4.23 requires numpy>=1.22, but you have numpy 1.21.5 which is incompatible.\n",
            "jaxlib 0.4.23+cuda12.cudnn89 requires numpy>=1.22, but you have numpy 1.21.5 which is incompatible.\n",
            "numba 0.58.1 requires numpy<1.27,>=1.22, but you have numpy 1.21.5 which is incompatible.\n",
            "pandas-gbq 0.19.2 requires google-auth-oauthlib>=0.7.0, but you have google-auth-oauthlib 0.4.6 which is incompatible.\n",
            "plotnine 0.12.4 requires numpy>=1.23.0, but you have numpy 1.21.5 which is incompatible.\n",
            "seaborn 0.13.1 requires matplotlib!=3.6.1,>=3.4, but you have matplotlib 3.6.1 which is incompatible.\n",
            "xarray-einstats 0.7.0 requires numpy>=1.22, but you have numpy 1.21.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed PyWavelets-1.4.1 dacite-1.8.1 dask-2023.3.1 dataclass_array-1.5.1 einops-0.7.0 einsum-0.3.0 gast-0.4.0 google-auth-2.16.2 google-auth-oauthlib-0.4.6 immutabledict-2.2.0 keras-2.11.0 lark-1.1.9 matplotlib-3.6.1 numpy-1.21.5 openexr-1.3.9 pillow-9.2.0 plotly-5.13.1 protobuf-3.19.6 pyarrow-10.0.0 scikit-image-0.20.0 scipy-1.10.1 setuptools-67.6.0 tensorboard-2.11.2 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.11.0 tensorflow-addons-0.23.0 tensorflow-datasets-4.9.0 tensorflow-estimator-2.11.0 tensorflow-metadata-1.13.0 tensorflow_graphics-2021.12.3 tensorflow_probability-0.19.0 trimesh-4.1.7 typeguard-2.13.3 visu3d-1.5.1 waymo-open-dataset-tf-2-11-0-1.6.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from waymo_open_dataset.v2.perception.utils import lidar_utils\n",
        "import numpy as np\n",
        "import os\n",
        "from typing import Optional\n",
        "import warnings\n",
        "# Disable annoying warnings from PyArrow using under the hood.\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "import dask.dataframe as dd\n",
        "from waymo_open_dataset import v2\n",
        "\n",
        "\n",
        "# ! mkdir lidar\n",
        "# ! mkdir lidar_segmentation\n",
        "# ! mkdir lidar_camera_projection\n",
        "# ! mkdir lidar_calibration\n",
        "# ! mkdir stats\n",
        "# ! mkdir vehicle_pose\n",
        "# ! mkdir lidar_pose\n",
        "! mkdir outputs\n",
        "# Path to the directory with all components\n",
        "dataset_dir = './'\n",
        "\n",
        "\n",
        "context_name = '15832924468527961_1564_160_1584_160'\n",
        "context_name = '10096619443888687526_2820_000_2840_000'\n",
        "\n",
        "def read(tag: str) -> dd.DataFrame:\n",
        "  \"\"\"Creates a Dask DataFrame for the component specified by its tag.\"\"\"\n",
        "  paths = tf.io.gfile.glob(f'{dataset_dir}/{tag}/{context_name}.parquet')\n",
        "  return dd.read_parquet(paths)\n",
        "\n",
        "\n",
        "lidar_calibration_df = read('lidar_calibration')\n",
        "lidar_df = read('lidar')\n",
        "lidar_pose_df = read('lidar_pose')\n",
        "lidar_camera_df = read('lidar_camera_projection')\n",
        "lidar_segmentation_df = read('lidar_segmentation')\n",
        "vehicle_pose_df = read('vehicle_pose')\n",
        "\n",
        "laser_index = 1\n",
        "\n",
        "def map_labels_to_point_cloud(points_tensor: tf.Tensor, labels_range_image: tf.Tensor, range_image_mask: tf.Tensor) -> tf.Tensor:\n",
        "    \"\"\"\n",
        "    Maps segmentation labels to each point in the point cloud.\n",
        "\n",
        "    Args:\n",
        "        points_tensor: A [N, D] tensor of 3D LiDAR points, where N is the number of points and D is the point dimensionality.\n",
        "        labels_range_image: A tensor of segmentation labels corresponding to the range image.\n",
        "        range_image_mask: A boolean tensor indicating valid points in the range image.\n",
        "\n",
        "    Returns:\n",
        "        A [N,] tensor of segmentation labels corresponding to each point in the point cloud.\n",
        "    \"\"\"\n",
        "    # Utiliser le masque de l'image de portée pour sélectionner les labels correspondants aux points valides\n",
        "    valid_labels = tf.gather_nd(labels_range_image, tf.where(range_image_mask))\n",
        "\n",
        "    return valid_labels\n",
        "\n",
        "def processing(lidar_df, lidar_pose_df, lidar_calibration_df, lidar_segmentation_df, vehicle_pose_df, folder, laser_index = 1):\n",
        "  lidar_df_filtered = lidar_df[lidar_df['key.laser_name'] == laser_index].compute()\n",
        "  lidar_pose_df_filtered = lidar_pose_df[lidar_pose_df['key.laser_name'] == laser_index].compute()\n",
        "\n",
        "\n",
        "  # faire une boucle sur l'ensemble des lignes sélectionnées (lidar_segmentation sans doute, du coup pas besoin de trier avec le laser 1)\n",
        "  vehicle_pose_df_pd = vehicle_pose_df.compute()\n",
        "  lidar_segmentation_df = lidar_segmentation_df.compute()\n",
        "  lidar_calibration = lidar_calibration_df[lidar_calibration_df['key.laser_name'] == laser_index].compute().iloc[0].to_dict()\n",
        "  lidar_calibration = v2.LiDARCalibrationComponent.from_dict(lidar_calibration)\n",
        "  for index in lidar_segmentation_df.index :\n",
        "    vehicle_pose = v2.VehiclePoseComponent.from_dict(vehicle_pose_df_pd.loc[index].to_dict())\n",
        "    lidar = v2.LiDARComponent.from_dict(lidar_df_filtered.loc[index].to_dict())\n",
        "    lidar_pose = v2.LiDARPoseComponent.from_dict(lidar_pose_df_filtered.loc[index].to_dict())\n",
        "    lidar_segmentation = v2.LiDARSegmentationLabelComponent.from_dict(lidar_segmentation_df.loc[index].to_dict())\n",
        "    points1 = lidar_utils.convert_range_image_to_point_cloud(lidar.range_image_return1,\n",
        "                                                            lidar_calibration,\n",
        "                                                            lidar_pose.range_image_return1,\n",
        "                                                            vehicle_pose,\n",
        "                                                            True)\n",
        "    points2 = lidar_utils.convert_range_image_to_point_cloud(lidar.range_image_return2,\n",
        "                                                            lidar_calibration,\n",
        "                                                            lidar_pose.range_image_return1,\n",
        "                                                            vehicle_pose,\n",
        "                                                            True)\n",
        "    shapes1 = lidar_segmentation.range_image_return1.shape\n",
        "\n",
        "    point_cloud = np.concatenate((points1.numpy(), points2.numpy()), axis=0)\n",
        "    point_cloud = point_cloud[:,[3,4,5,1]] # On récupère (x,y,z, intensity) la range étant calculé dans le dataloader\n",
        "\n",
        "    labels_range_image = tf.convert_to_tensor(lidar_segmentation.range_image_return1.values.reshape(shapes1[0], shapes1[1], 2)[:,:,1])\n",
        "\n",
        "    range_image_mask = tf.convert_to_tensor(lidar.range_image_return1.values.reshape(shapes1[0], shapes1[1], 4))[..., 0] > 0\n",
        "    seg1 = map_labels_to_point_cloud(points1, labels_range_image, range_image_mask)\n",
        "    shapes2 = lidar_segmentation.range_image_return2.shape\n",
        "    labels_range_image = tf.convert_to_tensor(lidar_segmentation.range_image_return2.values.reshape(shapes2[0], shapes2[1], 2)[:,:,1])\n",
        "    range_image_mask = tf.convert_to_tensor(lidar.range_image_return2.values.reshape(shapes2[0], shapes2[1], 4))[..., 0] > 0\n",
        "    seg2 = map_labels_to_point_cloud(points2, labels_range_image, range_image_mask)\n",
        "    segmentation = np.concatenate((seg1.numpy(), seg2.numpy()), axis=0, dtype=np.int16)\n",
        "    segmentation.tofile(os.path.join(folder,f'{index}.label'))\n",
        "    point_cloud.astype(np.float32).tofile(os.path.join(folder,f'{index}.bin'))\n",
        "\n",
        "def save_ply(filename, points):\n",
        "    \"\"\"\n",
        "    Enregistre un tableau de points dans un fichier PLY.\n",
        "\n",
        "    Paramètres :\n",
        "    - filename : le nom du fichier à créer.\n",
        "    - points : un tableau NumPy de points 3D, de forme (N, 3).\n",
        "    \"\"\"\n",
        "\n",
        "    header = \"\"\"ply\n",
        "format ascii 1.0\n",
        "element vertex {}\n",
        "property float x\n",
        "property float y\n",
        "property float z\n",
        "end_header\n",
        "\"\"\".format(len(points))\n",
        "\n",
        "    with open(filename, 'w') as f:\n",
        "        f.write(header)\n",
        "        for point in points:\n",
        "            f.write(\"{} {} {}\\n\".format(point[0], point[1], point[2]))\n",
        "\n",
        "folder = './outputs'\n",
        "processing(lidar_df, lidar_pose_df, lidar_calibration_df, lidar_segmentation_df, vehicle_pose_df, folder, laser_index = 1)"
      ],
      "metadata": {
        "id": "LS5-yDENbWml"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "points_loaded = np.fromfile(\"/content/15832924468527961_1564_160_1584_160;1507678843290833.bin\", dtype=np.float32).reshape(-1,5)\n",
        "segm_loaded = np.fromfile(\"/content/15832924468527961_1564_160_1584_160;1507678843290833.label\", dtype=np.int16)\n",
        "# save_ply(\"points_loaded.ply\",points_loaded)\n",
        "save_ply_with_labels(\"points_label_2.ply\", points_loaded, segm_loaded)"
      ],
      "metadata": {
        "id": "uxhk4Df9hZt1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_ply(filename, points):\n",
        "    \"\"\"\n",
        "    Enregistre un tableau de points dans un fichier PLY.\n",
        "\n",
        "    Paramètres :\n",
        "    - filename : le nom du fichier à créer.\n",
        "    - points : un tableau NumPy de points 3D, de forme (N, 3).\n",
        "    \"\"\"\n",
        "    header = \"\"\"ply\n",
        "format ascii 1.0\n",
        "element vertex {}\n",
        "property float x\n",
        "property float y\n",
        "property float z\n",
        "end_header\n",
        "\"\"\".format(len(points))\n",
        "\n",
        "    with open(filename, 'w') as f:\n",
        "        f.write(header)\n",
        "        for point in points:\n",
        "            f.write(\"{} {} {}\\n\".format(point[0], point[1], point[2]))"
      ],
      "metadata": {
        "id": "sNK1wRN1yOUY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_ply_with_labels(filename, points, labels):\n",
        "    \"\"\"\n",
        "    Enregistre un tableau de points et leurs labels de segmentation dans un fichier PLY.\n",
        "\n",
        "    Paramètres :\n",
        "    - filename : le nom du fichier à créer.\n",
        "    - points : un tableau NumPy de points 3D, de forme (N, 3).\n",
        "    - labels : un tableau NumPy de labels de segmentation, de forme (N,).\n",
        "    \"\"\"\n",
        "    header = \"\"\"ply\n",
        "format ascii 1.0\n",
        "element vertex {}\n",
        "property float x\n",
        "property float y\n",
        "property float z\n",
        "property uchar label\n",
        "end_header\n",
        "\"\"\".format(len(points))\n",
        "\n",
        "    with open(filename, 'w') as f:\n",
        "        f.write(header)\n",
        "        for point, label in zip(points, labels):\n",
        "            f.write(\"{} {} {} {}\\n\".format(point[0], point[1], point[2], label))"
      ],
      "metadata": {
        "id": "AUCP_V4657wD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_np = test.numpy()\n",
        "label_np[np.where(label_np == -1)] = 1"
      ],
      "metadata": {
        "id": "J4DEVVou7Las"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### LABEL\n",
        "1:  Car\n",
        "2:  Truck\n",
        "3:  Bus\n",
        "4:  Motorcyclist\n",
        "5:  Bicyclist\n",
        "6:  Pedestrian, Sign # ici l'erreur, il faudrait peut être corrigé avec la valeur -1 pour quand c'est non défini etc à voir.\n",
        "7:  Traffic Light\n",
        "8:  Pole\n",
        "9:  Construction Cone\n",
        "10: Bicycle\n",
        "11: Motorcycle\n",
        "12: Building\n",
        "13: Vegetation\n",
        "14: Tree Trunk\n",
        "15: Curb\n",
        "16: Road\n",
        "17: Lane Marker\n",
        "18: Walkable\n",
        "19: Sidewalk\n",
        "20: Other Ground\n",
        "21: Other Vehicle\n",
        "22: Undefined\n"
      ],
      "metadata": {
        "id": "SIT2M1TQ3GkJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! zip -r outputs.zip outputs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dAWWYLJd2zY3",
        "outputId": "619c9d88-987c-476d-f4fe-afb0e294202c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: outputs/ (stored 0%)\n",
            "  adding: outputs/10096619443888687526_2820_000_2840_000;1553704659038341.label (deflated 97%)\n",
            "  adding: outputs/10096619443888687526_2820_000_2840_000;1553704666037777.label (deflated 96%)\n",
            "  adding: outputs/10096619443888687526_2820_000_2840_000;1553704665037180.label (deflated 96%)\n",
            "  adding: outputs/10096619443888687526_2820_000_2840_000;1553704666537962.label (deflated 96%)\n",
            "  adding: outputs/10096619443888687526_2820_000_2840_000;1553704653047230.label (deflated 96%)\n",
            "  adding: outputs/10096619443888687526_2820_000_2840_000;1553704659538004.bin (deflated 40%)\n",
            "  adding: outputs/10096619443888687526_2820_000_2840_000;1553704661537525.label (deflated 97%)\n",
            "  adding: outputs/10096619443888687526_2820_000_2840_000;1553704662037497.label (deflated 96%)\n",
            "  adding: outputs/10096619443888687526_2820_000_2840_000;1553704667538098.bin (deflated 38%)\n",
            "  adding: outputs/10096619443888687526_2820_000_2840_000;1553704656041476.label (deflated 96%)\n",
            "  adding: outputs/10096619443888687526_2820_000_2840_000;1553704655042954.bin (deflated 38%)\n",
            "  adding: outputs/10096619443888687526_2820_000_2840_000;1553704660037618.label (deflated 97%)\n",
            "  adding: outputs/10096619443888687526_2820_000_2840_000;1553704662537317.label (deflated 97%)\n",
            "  adding: outputs/10096619443888687526_2820_000_2840_000;1553704664537012.label (deflated 96%)\n",
            "  adding: outputs/10096619443888687526_2820_000_2840_000;1553704658038906.bin (deflated 40%)\n",
            "  adding: outputs/10096619443888687526_2820_000_2840_000;1553704665037180.bin (deflated 40%)\n",
            "  adding: outputs/10096619443888687526_2820_000_2840_000;1553704662537317.bin (deflated 41%)\n",
            "  adding: outputs/10096619443888687526_2820_000_2840_000;1553704656041476.bin (deflated 38%)\n",
            "  adding: outputs/10096619443888687526_2820_000_2840_000;1553704665537444.bin (deflated 39%)\n",
            "  adding: outputs/10096619443888687526_2820_000_2840_000;1553704660037618.bin (deflated 41%)\n",
            "  adding: outputs/10096619443888687526_2820_000_2840_000;1553704654543930.label (deflated 96%)\n",
            "  adding: outputs/10096619443888687526_2820_000_2840_000;1553704656540682.bin (deflated 39%)\n",
            "  adding: outputs/10096619443888687526_2820_000_2840_000;1553704667538098.label (deflated 96%)\n",
            "  adding: outputs/10096619443888687526_2820_000_2840_000;1553704663536828.label (deflated 96%)\n",
            "  adding: outputs/10096619443888687526_2820_000_2840_000;1553704655542158.bin (deflated 35%)\n",
            "  adding: outputs/10096619443888687526_2820_000_2840_000;1553704658538650.label (deflated 96%)\n",
            "  adding: outputs/10096619443888687526_2820_000_2840_000;1553704666037777.bin (deflated 39%)\n",
            "  adding: outputs/10096619443888687526_2820_000_2840_000;1553704653546051.bin (deflated 40%)\n",
            "  adding: outputs/10096619443888687526_2820_000_2840_000;1553704664537012.bin (deflated 40%)\n",
            "  adding: outputs/10096619443888687526_2820_000_2840_000;1553704662037497.bin (deflated 40%)\n",
            "  adding: outputs/10096619443888687526_2820_000_2840_000;1553704661537525.bin (deflated 40%)\n",
            "  adding: outputs/10096619443888687526_2820_000_2840_000;1553704663037022.label (deflated 96%)\n",
            "  adding: outputs/10096619443888687526_2820_000_2840_000;1553704654044959.label (deflated 96%)\n",
            "  adding: outputs/10096619443888687526_2820_000_2840_000;1553704659038341.bin (deflated 40%)\n",
            "  adding: outputs/10096619443888687526_2820_000_2840_000;1553704660537439.bin (deflated 41%)\n",
            "  adding: outputs/10096619443888687526_2820_000_2840_000;1553704658038906.label (deflated 96%)\n",
            "  adding: outputs/10096619443888687526_2820_000_2840_000;1553704667037968.label (deflated 96%)\n",
            "  adding: outputs/10096619443888687526_2820_000_2840_000;1553704655042954.label (deflated 96%)\n",
            "  adding: outputs/10096619443888687526_2820_000_2840_000;1553704657039883.bin (deflated 39%)\n",
            "  adding: outputs/10096619443888687526_2820_000_2840_000;1553704664036889.label (deflated 96%)\n",
            "  adding: outputs/10096619443888687526_2820_000_2840_000;1553704654543930.bin (deflated 39%)\n",
            "  adding: outputs/10096619443888687526_2820_000_2840_000;1553704666537962.bin (deflated 38%)\n",
            "  adding: outputs/10096619443888687526_2820_000_2840_000;1553704663536828.bin (deflated 41%)\n",
            "  adding: outputs/10096619443888687526_2820_000_2840_000;1553704657539258.bin (deflated 40%)\n",
            "  adding: outputs/10096619443888687526_2820_000_2840_000;1553704661037476.label (deflated 97%)\n",
            "  adding: outputs/10096619443888687526_2820_000_2840_000;1553704664036889.bin (deflated 41%)\n",
            "  adding: outputs/10096619443888687526_2820_000_2840_000;1553704655542158.label (deflated 96%)\n",
            "  adding: outputs/10096619443888687526_2820_000_2840_000;1553704654044959.bin (deflated 40%)\n",
            "  adding: outputs/10096619443888687526_2820_000_2840_000;1553704660537439.label (deflated 97%)\n",
            "  adding: outputs/10096619443888687526_2820_000_2840_000;1553704661037476.bin (deflated 41%)\n",
            "  adding: outputs/10096619443888687526_2820_000_2840_000;1553704656540682.label (deflated 96%)\n",
            "  adding: outputs/10096619443888687526_2820_000_2840_000;1553704663037022.bin (deflated 41%)\n",
            "  adding: outputs/10096619443888687526_2820_000_2840_000;1553704665537444.label (deflated 96%)\n",
            "  adding: outputs/10096619443888687526_2820_000_2840_000;1553704653546051.label (deflated 96%)\n",
            "  adding: outputs/10096619443888687526_2820_000_2840_000;1553704657539258.label (deflated 96%)\n",
            "  adding: outputs/10096619443888687526_2820_000_2840_000;1553704659538004.label (deflated 96%)\n",
            "  adding: outputs/10096619443888687526_2820_000_2840_000;1553704657039883.label (deflated 96%)\n",
            "  adding: outputs/10096619443888687526_2820_000_2840_000;1553704667037968.bin (deflated 39%)\n",
            "  adding: outputs/10096619443888687526_2820_000_2840_000;1553704658538650.bin (deflated 40%)\n",
            "  adding: outputs/10096619443888687526_2820_000_2840_000;1553704653047230.bin (deflated 40%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Car, Truck, Bus, Motorcyclist, Bicyclist, Pedestrian, Sign, Traffic Light, Pole, Construction Cone, Bicycle, Motorcycle, Building, Vegetation, Tree Trunk, Curb, Road, Lane Marker, Walkable, Sidewalk, Other Ground, Other Vehicle, Undefined"
      ],
      "metadata": {
        "id": "PVae9xX6nwls"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "H0zOZWMT3gVw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}